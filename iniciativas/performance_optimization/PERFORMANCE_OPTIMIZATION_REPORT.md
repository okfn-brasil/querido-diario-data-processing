# RelatÃ³rio de OtimizaÃ§Ã£o de Performance - Querido DiÃ¡rio Data Processing

## SumÃ¡rio Executivo

Este relatÃ³rio apresenta uma anÃ¡lise completa das oportunidades de melhoria de performance no pipeline de processamento de dados do Querido DiÃ¡rio, identificando gargalos crÃ­ticos e propondo soluÃ§Ãµes prÃ¡ticas com base na arquitetura atual do sistema.

**âš ï¸ REVISÃƒO (2025-11-28):** Este plano foi revisado para priorizar iniciativas que endereÃ§am problemas de **Out Of Memory (OOM)** em produÃ§Ã£o, que tÃªm sido crÃ­ticos e impactam a estabilidade do sistema.

**Status Atual:** O sistema processa documentos de forma sequencial, sem paralelizaÃ§Ã£o, com mÃºltiplos pontos de I/O bloqueante e carregamento completo de documentos em memÃ³ria.

**Impacto Estimado:** As otimizaÃ§Ãµes propostas podem reduzir o tempo de processamento em 60-80% e o consumo de memÃ³ria em 40-60%. **A prioridade agora Ã© reduzir o consumo de memÃ³ria para evitar crashes OOM.**

---

## 1. AnÃ¡lise da Arquitetura Atual

### 1.1 Componentes do Sistema

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   PostgreSQL    â”‚ â† Metadados dos diÃ¡rios
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Processamento  â”‚ â†â”€â”€â”€â”€â†’â”‚  Apache Tika     â”‚
â”‚   Sequencial    â”‚       â”‚  (ExtraÃ§Ã£o PDF)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Minio/S3       â”‚ â†â”€â”€â”€â”€â†’â”‚   OpenSearch     â”‚
â”‚  (Arquivos)     â”‚       â”‚   (IndexaÃ§Ã£o)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1.2 Fluxo de Processamento Atual

O pipeline principal (`gazette_text_extraction.py`) executa:

1. **Lista documentos** do PostgreSQL (todo o conjunto)
2. **Para cada documento** (sequencial):
   - Download do arquivo do Minio
   - ExtraÃ§Ã£o de texto via Apache Tika (HTTP sÃ­ncrono)
   - Upload do texto extraÃ­do para Minio
   - SegmentaÃ§Ã£o (se aplicÃ¡vel)
   - IndexaÃ§Ã£o no OpenSearch
   - MarcaÃ§Ã£o como processado no PostgreSQL
   - Garbage collection manual

### 1.3 Gargalos Identificados

| Gargalo | LocalizaÃ§Ã£o | Impacto | Severidade | Impacto OOM |
|---------|-------------|---------|------------|-------------|
| **Query sem PaginaÃ§Ã£o** | `list_gazettes_to_be_processed.py:54-55` | MÃ©dio | ğŸ”´ **CRÃTICO OOM** | ğŸ”¥ Causa OOM |
| **Carregamento Total em MemÃ³ria** | `text_extraction.py:43-50` | MÃ©dio | ğŸ”´ **CRÃTICO OOM** | ğŸ”¥ Causa OOM |
| **Processamento Sequencial** | `gazette_text_extraction.py:35-46` | Alto | ğŸŸ¡ CrÃ­tico | âš ï¸ RetÃ©m objetos |
| **Download/Upload SÃ­ncrono** | `gazette_text_extraction.py:166-174` | Alto | ğŸŸ¡ CrÃ­tico | âš ï¸ RetÃ©m buffers |
| **Apache Tika SÃ­ncrono** | `text_extraction.py:28-41` | Alto | ğŸŸ¡ CrÃ­tico | âš ï¸ RetÃ©m documentos |
| **IndexaÃ§Ã£o Individual** | `gazette_text_extraction.py:83-84` | MÃ©dio | ğŸŸ¡ Moderado | âš ï¸ Acumula payloads |
| **Embeddings sem Cache** | `gazette_excerpts_embedding_reranking.py:19-44` | Baixo | ğŸŸ¢ Menor | âœ… Baixo |

---

## 2. Oportunidades de OtimizaÃ§Ã£o

**ğŸ”¥ PRIORIDADES REVISADAS - FOCO EM OOM:**
1. **ğŸš¨ CrÃ­tico OOM** - Implementar IMEDIATAMENTE (previne crashes)
2. **âš¡ Alto OOM** - Implementar em seguida (reduz consumo significativo)
3. **ğŸ“Š MÃ©dio OOM** - Implementar apÃ³s estabilizaÃ§Ã£o
4. **âœ… Baixo OOM** - Pode aguardar

---

### 2.1 ~~Processamento em Batch de Documentos~~ **[DESPRIORI ZADO]** â­â­â­

**Problema:** Cada documento Ã© processado individualmente em loop sequencial.

**SoluÃ§Ã£o:** Implementar processamento em batch com controle de concorrÃªncia.

**BenefÃ­cios:**
- âœ… ReduÃ§Ã£o de 60-75% no tempo total de processamento
- âœ… Melhor utilizaÃ§Ã£o de CPU e rede
- âœ… ParalelizaÃ§Ã£o de I/O operations
- âœ… ReduÃ§Ã£o de overhead de conexÃµes

**Complexidade:** MÃ©dia

**Impacto OOM:** âš ï¸ Moderado (pode aumentar uso de memÃ³ria se nÃ£o controlado)

**âš ï¸ ATENÃ‡ÃƒO:** Implementar apenas APÃ“S resolver problemas crÃ­ticos de memÃ³ria (2.3 e 2.4), caso contrÃ¡rio pode **AGRAVAR** problemas de OOM ao processar mÃºltiplos documentos simultaneamente.

**Arquivos Afetados:**
- `tasks/gazette_text_extraction.py`
- `tasks/list_gazettes_to_be_processed.py`
- `main/__main__.py`

---

### 2.2 ~~Processamento AssÃ­ncrono com Concurrent Futures~~ **[POSTERGAR]** â­â­â­

**Problema:** OperaÃ§Ãµes de rede (download, upload, Apache Tika) sÃ£o sÃ­ncronas e bloqueantes.

**SoluÃ§Ã£o:** Usar `concurrent.futures.ThreadPoolExecutor` para I/O paralelo.

**BenefÃ­cios:**
- âœ… Processamento paralelo de mÃºltiplos documentos
- âœ… ReduÃ§Ã£o de 50-70% no tempo de I/O
- âœ… Melhor aproveitamento de recursos de rede
- âœ… CompatÃ­vel com arquitetura atual (sem mudanÃ§as complexas)

**Complexidade:** MÃ©dia

**Impacto OOM:** âš ï¸ **ALTO - Pode AGRAVAR OOM** se implementado sem correÃ§Ãµes de memÃ³ria

**âš ï¸ ATENÃ‡ÃƒO:** NÃƒO implementar antes de resolver 2.3 (Streaming) e 2.4 (PaginaÃ§Ã£o), pois paralelizar processos com alto consumo de memÃ³ria irÃ¡ **multiplicar o problema** e causar mais crashes.

**Arquivos Afetados:**
- `tasks/gazette_text_extraction.py`
- `storage/digital_ocean_spaces.py` (opcional: adicionar mÃ©todos async)

---

### 2.3 ğŸš¨ **[PRIORIDADE MÃXIMA - OOM]** Streaming de Arquivos Grandes â­â­â­â­â­

**Problema:** Arquivos sÃ£o carregados completamente na memÃ³ria durante download/upload, causando **crashes de OOM em produÃ§Ã£o**.

**SoluÃ§Ã£o:** Implementar streaming com chunks para arquivos grandes (ex: chunks de 8MB).

**BenefÃ­cios para OOM:**
- ğŸ”¥ **CRÃTICO:** Previne OOM durante processamento de arquivos grandes
- âœ… ReduÃ§Ã£o de 40-60% no consumo de memÃ³ria
- âœ… Possibilidade de processar arquivos maiores que a RAM disponÃ­vel
- âœ… Melhor estabilidade do sistema
- âœ… **Elimina causa raiz de crashes OOM**

**Complexidade:** Baixa-MÃ©dia

**Arquivos Afetados:**
- `storage/digital_ocean_spaces.py` (jÃ¡ tem `upload_file_multipart`)
- `data_extraction/text_extraction.py`
- `tasks/gazette_text_extraction.py`

**Nota:** O cÃ³digo jÃ¡ possui `upload_file_multipart` implementado mas nÃ£o Ã© utilizado.

**ğŸš¨ AÃ‡ÃƒO IMEDIATA:**
1. Modificar `digital_ocean_spaces.py` para fazer download em chunks
2. Modificar `text_extraction.py` para processar em streaming via Apache Tika
3. Usar `upload_file_multipart` jÃ¡ existente para uploads
4. Adicionar limite de memÃ³ria explÃ­cito (ex: `max_memory_per_file=100MB`)

---

### 2.4 ğŸš¨ **[PRIORIDADE MÃXIMA - OOM]** PaginaÃ§Ã£o PostgreSQL â­â­â­â­â­

**Problema:** Query carrega TODOS os documentos pendentes em memÃ³ria de uma vez, causando **OOM quando hÃ¡ muitos documentos para processar**.

**SoluÃ§Ã£o:** Implementar paginaÃ§Ã£o/cursor no PostgreSQL para carregar documentos em lotes.

**BenefÃ­cios para OOM:**
- ğŸ”¥ **CRÃTICO:** Previne OOM ao listar milhares de documentos
- âœ… Consumo de memÃ³ria constante independente do volume
- âœ… ReduÃ§Ã£o imediata de 60-90% no uso de memÃ³ria inicial
- âœ… **Elimina causa raiz de crashes OOM no inÃ­cio do processamento**

**Complexidade:** Baixa

**Arquivos Afetados:**
- `tasks/list_gazettes_to_be_processed.py`

**ğŸš¨ AÃ‡ÃƒO IMEDIATA:**
1. Adicionar parÃ¢metros `limit` e `offset` ou usar cursor PostgreSQL
2. Implementar iteraÃ§Ã£o por pÃ¡ginas (ex: 100-1000 docs por pÃ¡gina)
3. Processar cada pÃ¡gina antes de carregar a prÃ³xima

---

### 2.5 âš¡ **[ALTA PRIORIDADE - OOM]** Bulk Indexing no OpenSearch â­â­â­â­

**BenefÃ­cios:**
- âœ… ReduÃ§Ã£o de 70-90% no tempo de indexaÃ§Ã£o
- âœ… Menor overhead de rede
- âœ… Melhor throughput do OpenSearch
- âš ï¸ **Reduz acÃºmulo de payloads em memÃ³ria** (ajuda com OOM indiretamente)

**Impacto OOM:** âš¡ Moderado (reduz objetos acumulados em memÃ³ria)
- âœ… ReduÃ§Ã£o de conexÃµes HTTP

**Complexidade:** Baixa

**Arquivos Afetados:**
- `index/opensearch.py`
- `tasks/gazette_text_extraction.py`
- `tasks/gazette_themed_excerpts_extraction.py`

---

### 2.5 PaginaÃ§Ã£o de Queries no PostgreSQL â­â­â­

**Problema:** Queries carregam todos os registros de uma vez na memÃ³ria.

**SoluÃ§Ã£o:** Implementar cursor server-side e paginaÃ§Ã£o.

**BenefÃ­cios:**
- âœ… ReduÃ§Ã£o de 50-80% no consumo de memÃ³ria inicial
- âœ… InÃ­cio mais rÃ¡pido do processamento
- âœ… Melhor escalabilidade
- âœ… Streaming de dados do banco

**Complexidade:** Baixa

**Arquivos Afetados:**
- `database/postgresql.py`
- `tasks/list_gazettes_to_be_processed.py`

---

### 2.6 Cache de Modelos de ML â­â­â­

**Problema:** Modelo BERT Ã© carregado para cada tema/batch de processamento.

**SoluÃ§Ã£o:** Implementar cache singleton do modelo em memÃ³ria.

**BenefÃ­cios:**
- âœ… ReduÃ§Ã£o de 90% no tempo de inicializaÃ§Ã£o de embeddings
- âœ… Menor uso de disco e rede
- âœ… Processamento mais rÃ¡pido

**Complexidade:** Baixa

**Arquivos Afetados:**
- `tasks/gazette_excerpts_embedding_reranking.py`

---

### 2.7 Connection Pooling â­â­â­

**Problema:** Cada operaÃ§Ã£o cria novas conexÃµes com serviÃ§os externos.

**SoluÃ§Ã£o:** Implementar connection pools para PostgreSQL, OpenSearch e S3.

**BenefÃ­cios:**
- âœ… ReduÃ§Ã£o de 30-50% em overhead de conexÃ£o
- âœ… Melhor performance em operaÃ§Ãµes repetidas
- âœ… Maior estabilidade
- âœ… Melhor controle de recursos

**Complexidade:** MÃ©dia

**Arquivos Afetados:**
- `database/postgresql.py`
- `index/opensearch.py`
- `storage/digital_ocean_spaces.py`

---

### 2.8 CompressÃ£o de Dados em TrÃ¢nsito â­â­

**Problema:** Textos grandes sÃ£o transferidos sem compressÃ£o entre serviÃ§os.

**SoluÃ§Ã£o:** Implementar compressÃ£o gzip para uploads/downloads de texto.

**BenefÃ­cios:**
- âœ… ReduÃ§Ã£o de 60-80% no trÃ¡fego de rede
- âœ… TransferÃªncias mais rÃ¡pidas
- âœ… Menor custo de storage (especialmente em cloud)

**Complexidade:** Baixa

**Arquivos Afetados:**
- `storage/digital_ocean_spaces.py`
- `tasks/gazette_text_extraction.py`

---

### 2.9 Retry Logic com Backoff Exponencial â­â­â­

**Problema:** Falhas temporÃ¡rias em serviÃ§os externos causam perda de documentos processados.

**SoluÃ§Ã£o:** Implementar retry com backoff exponencial e circuit breaker.

**BenefÃ­cios:**
- âœ… Maior resiliÃªncia a falhas temporÃ¡rias
- âœ… Melhor taxa de sucesso no processamento
- âœ… Menor necessidade de reprocessamento manual

**Complexidade:** Baixa-MÃ©dia

**Arquivos Afetados:**
- `data_extraction/text_extraction.py`
- `storage/digital_ocean_spaces.py`
- `index/opensearch.py`

---

### 2.10 Processamento Incremental Inteligente â­â­

**Problema:** Modo `UNPROCESSED` verifica flag booleana simples, mas documentos podem falhar parcialmente.

**SoluÃ§Ã£o:** Implementar estados de processamento mais granulares e checkpoints.

**BenefÃ­cios:**
- âœ… RecuperaÃ§Ã£o mais eficiente de falhas
- âœ… Reprocessamento seletivo de etapas
- âœ… Melhor rastreabilidade

**Complexidade:** MÃ©dia

**Arquivos Afetados:**
- `database/postgresql.py`
- `tasks/gazette_text_extraction.py`
- Schema do banco de dados

---

## 3. Plano de ImplementaÃ§Ã£o

### Fase 1: Quick Wins (1-2 semanas) ğŸš€

**Objetivo:** Ganhos rÃ¡pidos com baixo risco

#### Prioridade 1.1 - Bulk Indexing OpenSearch
- **EsforÃ§o:** 2-3 dias
- **Impacto:** Alto (70-90% reduÃ§Ã£o em tempo de indexaÃ§Ã£o)
- **Risco:** Baixo

**Tarefas:**
1. Adicionar mÃ©todo `bulk_index()` em `index/opensearch.py`
2. Modificar `gazette_text_extraction.py` para acumular documentos
3. Implementar flush automÃ¡tico a cada 100 documentos
4. Adicionar testes unitÃ¡rios e de integraÃ§Ã£o

#### Prioridade 1.2 - PaginaÃ§Ã£o PostgreSQL
- **EsforÃ§o:** 1-2 dias
- **Impacto:** MÃ©dio (50-80% reduÃ§Ã£o em memÃ³ria)
- **Risco:** Baixo

**Tarefas:**
1. Modificar `postgresql.py` para usar server-side cursor
2. Implementar generator com fetch size configurÃ¡vel
3. Atualizar `list_gazettes_to_be_processed.py`
4. Adicionar testes

#### Prioridade 1.3 - Cache de Modelo ML
- **EsforÃ§o:** 1 dia
- **Impacto:** MÃ©dio (90% reduÃ§Ã£o em tempo de carregamento)
- **Risco:** Baixo

**Tarefas:**
1. Criar singleton para gerenciar cache do modelo
2. Modificar `gazette_excerpts_embedding_reranking.py`
3. Adicionar limpeza de memÃ³ria adequada

#### Prioridade 1.4 - Usar Multipart Upload Existente
- **EsforÃ§o:** 0.5 dia
- **Impacto:** MÃ©dio (melhoria em estabilidade)
- **Risco:** Baixo

**Tarefas:**
1. Modificar `gazette_text_extraction.py` para usar `upload_file_multipart`
2. Adicionar lÃ³gica de detecÃ§Ã£o de tamanho de arquivo
3. Testar com arquivos grandes

---

### Fase 2: Processamento Paralelo (2-3 semanas) ğŸ”¥

**Objetivo:** ParalelizaÃ§Ã£o com ThreadPoolExecutor

#### Prioridade 2.1 - Processamento em Batch
- **EsforÃ§o:** 5-7 dias
- **Impacto:** Muito Alto (60-75% reduÃ§Ã£o em tempo total)
- **Risco:** MÃ©dio

**Tarefas:**
1. Criar mÃ³dulo `tasks/batch_processor.py`
2. Implementar `BatchProcessor` com configuraÃ§Ã£o de tamanho de batch
3. Adicionar controle de concorrÃªncia (max workers)
4. Implementar coleta de mÃ©tricas (tempo, sucesso, falhas)
5. Adicionar testes de carga

#### Prioridade 2.2 - I/O AssÃ­ncrono com ThreadPool
- **EsforÃ§o:** 5-7 dias
- **Impacto:** Alto (50-70% reduÃ§Ã£o em I/O)
- **Risco:** MÃ©dio

**Tarefas:**
1. Modificar `gazette_text_extraction.py` para usar ThreadPoolExecutor
2. Paralelizar download, Apache Tika, upload
3. Implementar tratamento de exceÃ§Ãµes em threads
4. Adicionar rate limiting para Apache Tika
5. Testes de stress

#### Prioridade 2.3 - Connection Pooling
- **EsforÃ§o:** 3-4 dias
- **Impacto:** MÃ©dio (30-50% reduÃ§Ã£o em overhead)
- **Risco:** MÃ©dio

**Tarefas:**
1. Adicionar `psycopg2.pool` em `postgresql.py`
2. Implementar pool para OpenSearch
3. Configurar pool do boto3 para S3
4. Ajustar configuraÃ§Ãµes de pool (min, max connections)

---

### Fase 3: Streaming e ResiliÃªncia (2-3 semanas) ğŸ’ª

**Objetivo:** Streaming de arquivos e maior resiliÃªncia

#### Prioridade 3.1 - Streaming de Arquivos
- **EsforÃ§o:** 5-6 dias
- **Impacto:** Alto (40-60% reduÃ§Ã£o em memÃ³ria)
- **Risco:** MÃ©dio

**Tarefas:**
1. Modificar `download_gazette_file` para stream com chunks
2. Adaptar Apache Tika para aceitar streams
3. Implementar threshold para escolher entre memory/stream
4. Adicionar compressÃ£o gzip nos streams
5. Testes com arquivos grandes (>100MB)

#### Prioridade 3.2 - Retry Logic
- **EsforÃ§o:** 3-4 dias
- **Impacto:** MÃ©dio (melhoria em resiliÃªncia)
- **Risco:** Baixo

**Tarefas:**
1. Adicionar biblioteca `tenacity` ou implementar retry decorator
2. Aplicar em todas as chamadas de rede
3. Configurar backoff exponencial (2^n segundos)
4. Adicionar circuit breaker para Apache Tika
5. Logging detalhado de retries

#### Prioridade 3.3 - Estados de Processamento
- **EsforÃ§o:** 4-5 dias
- **Impacto:** MÃ©dio (melhor rastreabilidade)
- **Risco:** MÃ©dio-Alto (mudanÃ§a de schema)

**Tarefas:**
1. Criar migration para adicionar coluna `processing_state`
2. Definir estados: `pending`, `downloading`, `extracting`, `uploading`, `indexing`, `completed`, `failed`
3. Implementar checkpointing em cada etapa
4. Adicionar recovery automÃ¡tico
5. Dashboard de monitoramento (opcional)

---

### Fase 4: OtimizaÃ§Ãµes AvanÃ§adas (2-3 semanas) ğŸš€

**Objetivo:** OtimizaÃ§Ãµes mais sofisticadas

#### Prioridade 4.1 - Fila de Processamento (Celery/RQ)
- **EsforÃ§o:** 7-10 dias
- **Impacto:** Alto (escalabilidade horizontal)
- **Risco:** Alto

**Tarefas:**
1. Avaliar Celery vs RQ vs Python-RQ
2. Configurar Redis como broker
3. Criar tasks assÃ­ncronas para cada etapa
4. Implementar retry e dead letter queue
5. Dashboard de monitoramento (Flower)

#### Prioridade 4.2 - Cache DistribuÃ­do (Redis)
- **EsforÃ§o:** 3-4 dias
- **Impacto:** MÃ©dio (reduÃ§Ã£o de reprocessamento)
- **Risco:** MÃ©dio

**Tarefas:**
1. Adicionar Redis ao docker-compose
2. Implementar cache de texto extraÃ­do
3. Cache de embeddings jÃ¡ calculados
4. Configurar TTL e polÃ­ticas de eviction

#### Prioridade 4.3 - Processamento DistribuÃ­do Multi-Worker
- **EsforÃ§o:** 5-7 dias
- **Impacto:** Muito Alto (escalabilidade horizontal)
- **Risco:** Alto

**Tarefas:**
1. Implementar particionamento de trabalho
2. CoordenaÃ§Ã£o via PostgreSQL ou Redis
3. Worker pools independentes
4. Load balancing
5. Health checks

---

## 4. Exemplo de CÃ³digo: ImplementaÃ§Ã£o de Batch Processing

```python
# tasks/batch_processor.py
from concurrent.futures import ThreadPoolExecutor, as_completed
from typing import Dict, List, Callable
import logging

class BatchProcessor:
    def __init__(self, batch_size: int = 10, max_workers: int = 4):
        self.batch_size = batch_size
        self.max_workers = max_workers
        
    def process_batch(
        self,
        items: List[Dict],
        process_func: Callable,
        **kwargs
    ) -> List[Dict]:
        """Process items in parallel batches"""
        results = []
        failed = []
        
        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            # Submit all tasks
            future_to_item = {
                executor.submit(process_func, item, **kwargs): item 
                for item in items
            }
            
            # Collect results as they complete
            for future in as_completed(future_to_item):
                item = future_to_item[future]
                try:
                    result = future.result()
                    results.append(result)
                except Exception as e:
                    logging.error(f"Failed to process {item['file_path']}: {e}")
                    failed.append(item)
                    
        return results, failed

# Uso em gazette_text_extraction.py
def extract_text_from_gazettes_batch(
    gazettes: Iterable[Dict[str, Any]],
    territories: Iterable[Dict[str, Any]],
    database: DatabaseInterface,
    storage: StorageInterface,
    index: IndexInterface,
    text_extractor: TextExtractorInterface,
    batch_size: int = 10,
    max_workers: int = 4,
) -> List[str]:
    """
    Extracts text from gazettes using batch processing
    """
    processor = BatchProcessor(batch_size, max_workers)
    
    all_ids = []
    gazette_batch = []
    
    for gazette in gazettes:
        gazette_batch.append(gazette)
        
        if len(gazette_batch) >= batch_size:
            results, failed = processor.process_batch(
                gazette_batch,
                try_process_gazette_file,
                territories=territories,
                database=database,
                storage=storage,
                index=index,
                text_extractor=text_extractor,
            )
            
            # Bulk index the results
            if results:
                document_ids = [r for result in results for r in result]
                all_ids.extend(document_ids)
                
            gazette_batch = []
            gc.collect()
    
    # Process remaining
    if gazette_batch:
        results, failed = processor.process_batch(
            gazette_batch,
            try_process_gazette_file,
            territories=territories,
            database=database,
            storage=storage,
            index=index,
            text_extractor=text_extractor,
        )
        all_ids.extend([r for result in results for r in result])
    
    return all_ids
```

---

## 5. Exemplo de CÃ³digo: Bulk Indexing OpenSearch

```python
# index/opensearch.py - Adicionar mÃ©todo
def bulk_index(
    self,
    documents: List[Dict],
    index: str = "",
    refresh: bool = False,
) -> Dict:
    """
    Bulk index multiple documents at once
    """
    index = self.get_index_name(index)
    
    # Prepare bulk request body
    bulk_body = []
    for doc in documents:
        doc_id = doc.pop('_id', None)
        action = {'index': {'_index': index}}
        if doc_id:
            action['index']['_id'] = doc_id
        bulk_body.append(action)
        bulk_body.append(doc)
    
    if not bulk_body:
        return {'items': []}
    
    response = self._search_engine.bulk(
        body=bulk_body,
        refresh=refresh,
        request_timeout=120
    )
    
    # Check for errors
    if response.get('errors'):
        failed = [
            item for item in response['items'] 
            if item.get('index', {}).get('status', 200) >= 400
        ]
        logging.warning(f"Bulk index had {len(failed)} failures")
    
    return response

# Uso em gazette_text_extraction.py
def try_process_gazette_file_batch(
    gazettes: List[Dict],
    territories: Iterable[Dict[str, Any]],
    database: DatabaseInterface,
    storage: StorageInterface,
    index: IndexInterface,
    text_extractor: TextExtractorInterface,
) -> List[str]:
    """Process multiple gazettes and bulk index"""
    
    documents_to_index = []
    
    for gazette in gazettes:
        # ... processing logic ...
        gazette["source_text"] = try_to_extract_content(gazette_file, text_extractor)
        # ... rest of processing ...
        
        if gazette_type_is_aggregated(gazette):
            segmenter = get_segmenter(gazette["territory_id"], territories)
            segments = segmenter.get_gazette_segments(gazette)
            for segment in segments:
                segment['_id'] = segment['file_checksum']
                documents_to_index.append(segment)
        else:
            gazette['_id'] = gazette['file_checksum']
            documents_to_index.append(gazette)
    
    # Bulk index all documents
    if documents_to_index:
        index.bulk_index(documents_to_index, refresh=True)
    
    # Bulk update database
    for gazette in gazettes:
        set_gazette_as_processed(gazette, database)
    
    return [doc['_id'] for doc in documents_to_index]
```

---

## 6. Exemplo de CÃ³digo: Streaming de Arquivos

```python
# storage/digital_ocean_spaces.py - Adicionar mÃ©todo
def get_file_stream(
    self, 
    file_key: str, 
    chunk_size: int = 8192
) -> Iterator[bytes]:
    """
    Stream file from storage in chunks
    """
    response = self._client.get_object(
        Bucket=self._bucket,
        Key=str(file_key)
    )
    
    stream = response['Body']
    try:
        while True:
            chunk = stream.read(chunk_size)
            if not chunk:
                break
            yield chunk
    finally:
        stream.close()

# data_extraction/text_extraction.py - Modificar
def _try_extract_text_streaming(self, filepath: str, file_size: int) -> str:
    """
    Extract text using streaming for large files
    """
    # Use streaming for files > 10MB
    if file_size > 10 * 1024 * 1024:
        with open(filepath, "rb") as file:
            headers = {
                "Content-Type": self._get_file_type(filepath),
                "Accept": "text/plain",
            }
            
            # Stream to Apache Tika
            response = requests.put(
                f"{self._url}/tika",
                data=self._chunk_generator(file),
                headers=headers,
                stream=True
            )
            
            # Collect response in chunks
            text_chunks = []
            for chunk in response.iter_content(chunk_size=8192, decode_unicode=True):
                if chunk:
                    text_chunks.append(chunk)
            
            return ''.join(text_chunks)
    else:
        return self._try_extract_text(filepath)

def _chunk_generator(self, file, chunk_size=8192):
    """Generator for file chunks"""
    while True:
        chunk = file.read(chunk_size)
        if not chunk:
            break
        yield chunk
```

---

## 7. MÃ©tricas e Monitoramento

### 7.1 KPIs para Acompanhar

| MÃ©trica | Baseline Atual | Meta Fase 1 | Meta Fase 2 | Meta Fase 3 |
|---------|---------------|-------------|-------------|-------------|
| **Tempo mÃ©dio por documento** | ~10s | ~8s (-20%) | ~4s (-60%) | ~3s (-70%) |
| **Throughput (docs/hora)** | ~360 | ~450 (+25%) | ~900 (+150%) | ~1200 (+233%) |
| **Uso de memÃ³ria (pico)** | 100% | 70% (-30%) | 50% (-50%) | 40% (-60%) |
| **Taxa de falha** | 5-10% | 3-5% | 1-2% | <1% |
| **Tempo de indexaÃ§Ã£o** | 100% | 20% (-80%) | 15% | 10% |
| **Escalabilidade (workers)** | 1 | 1 | 4 | N |

### 7.2 InstrumentaÃ§Ã£o Recomendada

```python
# tasks/metrics.py
import time
import logging
from functools import wraps

class ProcessingMetrics:
    def __init__(self):
        self.total_processed = 0
        self.total_failed = 0
        self.total_time = 0
        self.stage_times = {}
    
    def record_processing(self, stage: str):
        """Decorator to record processing time"""
        def decorator(func):
            @wraps(func)
            def wrapper(*args, **kwargs):
                start = time.time()
                try:
                    result = func(*args, **kwargs)
                    self.total_processed += 1
                    return result
                except Exception as e:
                    self.total_failed += 1
                    raise
                finally:
                    duration = time.time() - start
                    self.total_time += duration
                    self.stage_times.setdefault(stage, []).append(duration)
                    logging.info(f"{stage} took {duration:.2f}s")
            return wrapper
        return decorator
    
    def get_report(self) -> Dict:
        """Generate performance report"""
        return {
            'total_processed': self.total_processed,
            'total_failed': self.total_failed,
            'success_rate': self.total_processed / (self.total_processed + self.total_failed),
            'avg_time_per_doc': self.total_time / self.total_processed if self.total_processed > 0 else 0,
            'stage_averages': {
                stage: sum(times) / len(times)
                for stage, times in self.stage_times.items()
            }
        }
```

---

## 8. Riscos e MitigaÃ§Ãµes

| Risco | Probabilidade | Impacto | MitigaÃ§Ã£o |
|-------|--------------|---------|-----------|
| **ConcorrÃªncia causa corrupÃ§Ã£o de dados** | MÃ©dia | Alto | Implementar locks, transaÃ§Ãµes atÃ´micas, testes extensivos |
| **Memory leaks em processamento paralelo** | MÃ©dia | Alto | Profiling contÃ­nuo, limites de memÃ³ria, garbage collection |
| **Apache Tika sobrecarga** | Alta | MÃ©dio | Rate limiting, mÃºltiplas instÃ¢ncias, queue |
| **Deadlocks em connection pools** | Baixa | MÃ©dio | Timeouts adequados, monitoring, circuit breakers |
| **MudanÃ§as quebram compatibilidade** | Baixa | Alto | Feature flags, rollback plan, testes A/B |
| **Custos de infraestrutura aumentam** | MÃ©dia | MÃ©dio | Monitoramento de custos, auto-scaling inteligente |

---

## 9. Estimativas de Custo-BenefÃ­cio

### 9.1 EsforÃ§o Total Estimado

| Fase | DuraÃ§Ã£o | Desenvolvedores | EsforÃ§o (pessoa-dias) |
|------|---------|-----------------|----------------------|
| Fase 1 | 1-2 semanas | 1-2 | 10-15 dias |
| Fase 2 | 2-3 semanas | 2 | 25-35 dias |
| Fase 3 | 2-3 semanas | 2 | 25-35 dias |
| Fase 4 | 2-3 semanas | 2-3 | 30-45 dias |
| **Total** | **7-11 semanas** | **2-3** | **90-130 dias** |

### 9.2 Retorno Esperado

**CenÃ¡rio Base:** 10.000 documentos/dia

| MÃ©trica | Antes | Depois (Fase 2) | Economia |
|---------|-------|-----------------|----------|
| Tempo de processamento | 27.8 horas | 11.1 horas | 16.7 horas/dia |
| Custo de compute (estimado) | $50/dia | $25/dia | $750/mÃªs |
| Capacidade | 10k docs/dia | 25k docs/dia | +150% |

**ROI:** Break-even em ~2-3 meses considerando economia de infraestrutura e ganho de capacidade.

---

## 10. RecomendaÃ§Ãµes Finais - **REVISADO COM FOCO EM OOM**

### ğŸš¨ CRÃTICO - Implementar ESTA SEMANA (Previne Crashes OOM)

1. **ğŸ”¥ PaginaÃ§Ã£o PostgreSQL** - Evita carregar milhares de docs em memÃ³ria de uma vez
   - **Impacto:** Reduz 60-90% do uso de memÃ³ria inicial
   - **EsforÃ§o:** 1-2 dias
   - **Risco:** Muito baixo
   
2. **ğŸ”¥ Streaming de Arquivos** - Processa arquivos em chunks, nÃ£o carrega tudo em memÃ³ria
   - **Impacto:** Previne OOM em arquivos grandes (>50MB)
   - **EsforÃ§o:** 2-3 dias (cÃ³digo multipart jÃ¡ existe!)
   - **Risco:** Baixo

3. **ğŸ”¥ Garbage Collection ExplÃ­cito + Memory Limits** - Garante liberaÃ§Ã£o de memÃ³ria
   - **Impacto:** Reduz acÃºmulo de objetos entre documentos
   - **EsforÃ§o:** 1 dia
   - **Risco:** Muito baixo

### âš¡ ALTA PRIORIDADE - PrÃ³ximas 2 Semanas (Reduz Consumo)

4. **Bulk Indexing OpenSearch** - Reduz objetos acumulados em memÃ³ria
5. **Connection Pooling** - Evita acÃºmulo de conexÃµes abertas
6. **Retry Logic com Cleanup** - Garante limpeza em caso de erro

### ğŸ“Š MÃ‰DIA PRIORIDADE - ApÃ³s EstabilizaÃ§Ã£o (Semanas 3-4)

7. **Monitoramento de MemÃ³ria** - MÃ©tricas e alertas de uso
8. **Cache de Modelo ML** - Mas com limite de tamanho
9. **OtimizaÃ§Ã£o de Query PostgreSQL** - Reduz overhead

### âš ï¸ POSTERGAR - Implementar APENAS ApÃ³s Resolver OOM

10. **Processamento em Batch** - PODE AGRAVAR OOM se feito antes
11. **ThreadPoolExecutor/Async** - PODE AGRAVAR OOM se feito antes
12. **Multi-Worker DistribuÃ­do** - PODE AGRAVAR OOM se feito antes

### âŒ BAIXA PRIORIDADE - Futuro Distante

13. **Fila de Processamento (Celery)** - Apenas para escalabilidade horizontal
14. **Cache DistribuÃ­do** - Apenas se houver redundÃ¢ncia

---

## 11. PrÃ³ximos Passos - **PLANO DE AÃ‡ÃƒO OOM**

### ğŸš¨ AÃ‡ÃƒO IMEDIATA (HOJE - DIA 0)

1. âœ… **APROVAR este plano revisado com foco em OOM**
2. âœ… Alocar desenvolvedor(es) para Fase 0 com prioridade mÃ¡xima
3. âœ… Configurar monitoramento de memÃ³ria em produÃ§Ã£o (se ainda nÃ£o existe)
4. âœ… Criar ambiente de staging com limites de memÃ³ria similares a produÃ§Ã£o
5. âœ… Documentar casos recentes de OOM (logs, contexto, volume)

### ğŸ“… DIA 1-2: PaginaÃ§Ã£o PostgreSQL

1. ğŸš€ Implementar paginaÃ§Ã£o em `list_gazettes_to_be_processed.py`
2. ğŸ§ª Testar com 10k+ documentos pendentes
3. ğŸ“Š Medir uso de memÃ³ria antes/depois
4. âœ… Code review e merge

### ğŸ“… DIA 2-4: Streaming de Arquivos

1. ğŸš€ Implementar download em chunks
2. ğŸš€ Modificar integraÃ§Ã£o com Apache Tika para streaming
3. ğŸš€ Ativar `upload_file_multipart` existente
4. ğŸ§ª Testar com arquivos grandes (100MB+)
5. ğŸ“Š Medir uso de memÃ³ria durante processamento
6. âœ… Code review e merge

### ğŸ“… DIA 5: Deploy e ValidaÃ§Ã£o

1. ğŸš€ Deploy em staging
2. ğŸ§ª Processar 1000+ documentos reais
3. ğŸ“Š Monitorar memÃ³ria por 24 horas
4. âœ… Se estÃ¡vel, deploy em produÃ§Ã£o
5. ğŸ“Š Monitorar produÃ§Ã£o por 48-72 horas

### ğŸ“… SEMANA 2: Monitoramento e Ajustes

1. ğŸ“Š Coletar mÃ©tricas de produÃ§Ã£o
2. ğŸ› Corrigir problemas identificados
3. ğŸ“ Documentar liÃ§Ãµes aprendidas
4. âœ… **GATE:** Sistema deve estar estÃ¡vel por 1+ semana antes de prosseguir

### ğŸ“… SEMANA 3-4: Fase 1 (Se estÃ¡vel)

1. ğŸš€ Implementar Fase 1 (Bulk indexing, connection pooling)
2. ğŸ§ª Testes contÃ­nuos de memÃ³ria
3. ğŸ“Š Validar que nÃ£o hÃ¡ regressÃ£o de OOM

### â¸ï¸ PAUSAR E AVALIAR

- âœ… Sistema estÃ¡vel por 2+ semanas?
- âœ… Sem crashes OOM em produÃ§Ã£o?
- âœ… MÃ©tricas de memÃ³ria consistentes?
- âœ… **SE SIM:** Considerar Fase 2
- âŒ **SE NÃƒO:** Investigar e corrigir antes de prosseguir

---

## 12. ApÃªndices

### ApÃªndice A: Ferramentas Recomendadas

- **Profiling:** `cProfile`, `py-spy`, `memory_profiler`
- **Monitoring:** Prometheus + Grafana
- **Load Testing:** Locust, Apache Bench
- **Tracing:** OpenTelemetry (opcional)

### ApÃªndice B: Bibliotecas Ãšteis

```txt
# Adicionar ao requirements.txt
tenacity==8.2.3           # Retry logic
redis==5.0.0              # Caching (Fase 4)
celery==5.3.4             # Task queue (Fase 4)
python-json-logger==2.0.7 # Structured logging
```

### ApÃªndice C: ConfiguraÃ§Ãµes Recomendadas

```python
# config/performance.py
BATCH_SIZE = int(os.getenv('BATCH_SIZE', '10'))
MAX_WORKERS = int(os.getenv('MAX_WORKERS', '4'))
BULK_INDEX_SIZE = int(os.getenv('BULK_INDEX_SIZE', '100'))
DB_FETCH_SIZE = int(os.getenv('DB_FETCH_SIZE', '1000'))
STREAMING_THRESHOLD_MB = int(os.getenv('STREAMING_THRESHOLD_MB', '10'))
RETRY_MAX_ATTEMPTS = int(os.getenv('RETRY_MAX_ATTEMPTS', '3'))
RETRY_BACKOFF_FACTOR = float(os.getenv('RETRY_BACKOFF_FACTOR', '2'))

# Connection Pool Sizes
DB_POOL_SIZE = int(os.getenv('DB_POOL_SIZE', '5'))
DB_POOL_MAX = int(os.getenv('DB_POOL_MAX', '20'))
S3_POOL_SIZE = int(os.getenv('S3_POOL_SIZE', '10'))
```

---

## ConclusÃ£o - **REVISÃƒO COM FOCO EM OOM**

Este relatÃ³rio foi **REVISADO** para priorizar a soluÃ§Ã£o de problemas de **Out Of Memory (OOM)** que tÃªm causado crashes em produÃ§Ã£o. A priorizaÃ§Ã£o foi completamente alterada:

### âŒ Plano Original (Foco em Performance)
- Prioridade: ParalelizaÃ§Ã£o e velocidade
- Risco: **Poderia AGRAVAR problemas de OOM**
- Timeline: 7-11 semanas

### âœ… Plano Revisado (Foco em Estabilidade/OOM)
- Prioridade: ReduÃ§Ã£o de memÃ³ria e estabilidade
- BenefÃ­cio: **Elimina crashes de OOM primeiro, performance depois**
- Timeline: 3-5 dias para estabilizaÃ§Ã£o crÃ­tica

### ğŸ¯ MudanÃ§as Principais

1. **ğŸš¨ Fase 0 (NOVA):** EmergÃªncia OOM - 3-5 dias
   - PaginaÃ§Ã£o PostgreSQL (elimina picos iniciais)
   - Streaming de arquivos (elimina OOM em arquivos grandes)
   - Memory safeguards (garbage collection, limites)

2. **âš ï¸ POSTERGAR:** ParalelizaÃ§Ã£o e Async
   - ThreadPoolExecutor e batch processing foram **DESPRIORIZADOS**
   - Motivo: Podem **multiplicar** uso de memÃ³ria e agravar OOM
   - Implementar apenas APÃ“S sistema estÃ¡vel

3. **ğŸ“Š Foco em Monitoramento:** 
   - MÃ©tricas de memÃ³ria em tempo real
   - Gates de aprovaÃ§Ã£o entre fases
   - Rollback imediato se memÃ³ria aumentar

### ğŸš€ RecomendaÃ§Ã£o REVISADA

**CRÃTICO:** Implementar **Fase 0 IMEDIATAMENTE** (esta semana) antes de qualquer otimizaÃ§Ã£o de performance. Um sistema rÃ¡pido mas instÃ¡vel Ã© pior que um sistema lento mas confiÃ¡vel.

**NÃ£o prosseguir** com otimizaÃ§Ãµes de performance (batch, async, paralelizaÃ§Ã£o) atÃ© que:
1. âœ… Sistema estÃ¡vel por 2+ semanas sem OOM
2. âœ… MÃ©tricas de memÃ³ria consistentes
3. âœ… Volumes de produÃ§Ã£o processados com sucesso

---

**Documento criado em:** 2025-11-28  
**VersÃ£o:** 2.0 - **REVISADO PARA FOCO EM OOM**  
**Autores:** GitHub Copilot CLI - AnÃ¡lise de Codebase  
**Status:** âš ï¸ **PLANO DE AÃ‡ÃƒO EMERGENCIAL - APROVAÃ‡ÃƒO URGENTE NECESSÃRIA**
